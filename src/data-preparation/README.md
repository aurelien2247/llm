<h1 align="center">
    LLM from scratch
</h1>

<h4 align="center"> Ceci est un petit projet qui m'a permis de d√©couvrir les √©tapes basiques de tokenization et lacr√©ation d'embeddings pour l'entra√Ænement d'un mod√®le de langage. </h4>

<p align="center">
  <a href="#üéØ-Objectifs">Objectifs</a>
  <a href="#üíª-Utilisation">Utilisation</a>
  <a href="#ü§†-cr√©dits">Cr√©dit</a>
</p>

## Objectifs

Le but de ce d√©p√¥t est d'apprendre √† :
- tokeniser un texte (BPE via `tiktoken`),
- construire des paires (input, target) pour la t√¢che de next-token prediction,
- convertir token IDs en embeddings PyTorch (`nn.Embedding`), et
- Voir l'utilisation d'un `DataLoader` simple.

## Utilisation

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```


## ü§† Cr√©dits

<table>
    <tr>
        <td align="center">
            <a href="mailto:aurelien.moignet@imt-atlantique.net">
                <img src="https://avatars.githubusercontent.com/u/76565476?v=4" width="100px;" alt="Image de profil" style="border-radius: 100%"/>
                <br />
                <sub><b>Aur√©lien</b></sub>
            </a>
            <br />
        </td>
        <td align="center">
                <img src="https://avatars.githubusercontent.com/u/5618407?v=4" width="100px;" alt="Image de profil" style="border-radius: 100%"/>
                <br />
                <sub><b>Sebastian Raschka</b></sub>
                <sub><b>J'ai appris la cr√©ation des llms from scratch grace aux livres <a href="https://www.amazon.fr/Build-Large-Language-Model-Scratch/dp/1633437167">Build a Large Language Model from Scratch</a></b></sub>
            <br />
        </td>
    </tr>
</table>